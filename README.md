# Sales Reporting Pipeline ğŸš€

> ğŸ“Š A complete automated sales reporting solution using PostgreSQL, DBT, Power BI, and Apache Airflow.

![Dashboard Screenshot](https://your-screenshot-url-here) <!-- Replace with actual link -->

---

## ğŸ§¾ Tech Stack & Workflow

1. **Ingest** fresh CSV data using Python + SQLAlchemy â†’ PostgreSQL  
2. **Transform** data with DBT (models: `orders_summary`, `top_products`, `regional_sales`)  
3. **Visualize** with Power BI dashboard (`Sales_Overview.pbix`)  
4. **Automate** daily ingestion & DBT run using Airflow DAG (`sales_reporting_pipeline`)

---

## ğŸ“‚ Project Structure  
Sales_Reporting_Pipeline/
â”œâ”€â”€ superstore_sales_data.csv
â”œâ”€â”€ sales_overview_dashboard/
â”‚ â””â”€â”€ Sales_Overview.pbix
â”œâ”€â”€ CSV_Ingestion/
â”‚ â””â”€â”€ ingestion_code.ipynb
â”œâ”€â”€ sales_reporting_dbt/
â”‚ â”œâ”€â”€ dbt_project.yml
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ top_products.sql
â”‚ â”œâ”€â”€ regional_sales.sql
â”‚ â””â”€â”€ orders_summary.sql
â”œâ”€â”€ airflow_dags/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â””â”€â”€ sales_reporting_dag.py
â”‚ â””â”€â”€ scripts/
â”‚ â”œâ”€â”€ ingest_csv.py
â”‚ â””â”€â”€ run_dbt.bat
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md  


---

## ğŸ“Š Power BI Dashboard Highlights

- KPI Cards: **Total Sales, Total Profit, Total Orders, Avg Order Value**
- **Top Products by Sale** (Clustered Bar Chart)
- **Sales Distribution by Category** (Donut Chart)
- **Monthly Sales vs Orders** (Bar + Line Chart)
- **Regional Profit per Order** (Bar Chart)
- **Regional Monthly Sales** (Line Chart)
- **Dynamic slicers** for *Product Category*, *Subâ€‘Category*, and *Region*

---

## ğŸ•“ Airflow Automation (via Docker)

- **DAG Name**: `sales_reporting_pipeline`
- Triggers 2 daily tasks:
  1. CSV ingestion to PostgreSQL (`ingest_csv.py`)
  2. DBT model refresh (`run_dbt.bat`)
- Built inside Dockerized Apache Airflow environment
- Scheduled to run at 12:00 AM IST daily
- Validated in the Airflow UI

---

## âš™ï¸ How to Run Locally

1. Ensure Docker Desktop is running
2. Mount this repo's folders into your Airflow Docker environment:
   - `dags/ â†’ airflow_dags/dags`
   - `scripts/ â†’ airflow_dags/scripts`
3. Trigger the DAG from Airflow UI (`localhost:8080`)
4. Power BI dashboard connects to `Sales_Reporting` PostgreSQL DB for live visuals

---

## âœï¸ Author

**Chirag Sharma**  
_Data Engineering Intern â€¢ SQL â€¢ Python â€¢ DBT â€¢ Airflow â€¢ Power BI_  
ğŸ”— [GitHub Profile](https://github.com/Chirag-Sharmaaa)

---

## ğŸ“ Notes

- `logs/` and `.ipynb_checkpoints/` folders were excluded to keep the repo clean.
- Use `requirements.txt` to set up any missing Python dependencies locally.

---

